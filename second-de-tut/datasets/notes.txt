Data Architect - exactly like building a house, design house buleprint

                design how data will flow, integrate and be accessed. be scalable

                step 1: choose type of Data Architecture
                    1. data warehouse - structured data
                    2. data lake - flexible, semi,      unstructure along with structured
                    3. data lakehouse - mix of above. get flexibility of having any type of data and u can still organize and structure data
                    4. Data mesh - decentralized dms. 

                            1. Create a DWH
                        Inmon - sources -> stage -> enterprise dwh (3NF) -> data marts (design data for consumption) -> report
                        Stage

                        Kimball - stage -> data marts -> report - save time

                        Data vault - stage -> raw vault -> business vault -> data marts -> report

                        Medallion Architecture - source -> bronze [raw, unprocessed data, traceability and debugging] - Table - Full load[truncate and insert] - no transformation of data - no change in data model -
                         data engineers 

                         -> silver [clean, standardized data, prepare for analysis] Table - Full load - 
                         data cleaning, standardization, normalization, dervied columns, enrichment -  no change in data model - 
                         data analysis, engineers

                         -> gold   [business ready data, for analysis] - Views - none - 
                         data integration, aggregation, business rules and logic - 
                         start schema, aggregated object, flat tables (data models) - 
                         data analysist
                         business users

Separation of concerns
 break complex system into small simple part, each component is responsible for a function as seen above, each layer has own unique task -  important in data Architecture. 

 Always choose a naming convention before starting any work in relation to naming etc. 


    1. Build bronze layer. 

 Interview source system experts to understand the data sources. Helps design correct script -> Analysing 
    
            Understand the story behind the data,
             who owns the data, 
             which process it supports,
             system and data documentation
             data model and catalog

             understand business context 

            Architecture and tech stack
            How is data stored? on premise or cloud
            what are intgeration capabilities? api, kafka, file extract, 

            Extract & load
            Increment v Full load
            Data scope & historical needs
            expected size of extracts
            any data volume limitations
            how to avoid impacting source systems performance
            auth and author [token, ssh, keys, password, vpn, ip whitelisting]


            Bulk insert - operation loads data in one go to db. 


 Data Ingestion -> coding

 Data completedness and schema checks -> validating

 Doc and Verisioning